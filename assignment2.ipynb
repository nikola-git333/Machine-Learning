{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biblioteka za rad sa podatcima\n",
    "import pandas as pd\n",
    "\n",
    "# ucitavanje podataka\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "1H OCEAN      9136\n",
       "INLAND        6551\n",
       "ISLAND           5\n",
       "NEAR BAY      2290\n",
       "NEAR OCEAN    2658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('ocean_proximity').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uklonio sam spornu klasu *ISLAND* prije podjele podataka zato sto postoji samo 5 zapisa i dovelo bi do klasne nebalansiranosti, sto bi dovelo do problema tokom validacije i treniranja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ulazni skup i izlazni skup\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konverziju kategorickih podataka sam promjenio iz *OrdinalEncoder* u **OneHotEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>income_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10536</th>\n",
       "      <td>0.934115</td>\n",
       "      <td>-1.005494</td>\n",
       "      <td>-1.884754</td>\n",
       "      <td>-0.436118</td>\n",
       "      <td>-0.678455</td>\n",
       "      <td>-0.705163</td>\n",
       "      <td>-0.706757</td>\n",
       "      <td>2.499136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617070</td>\n",
       "      <td>0.997745</td>\n",
       "      <td>1.555668</td>\n",
       "      <td>-3.536063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12420</th>\n",
       "      <td>1.688241</td>\n",
       "      <td>-0.907501</td>\n",
       "      <td>-0.213514</td>\n",
       "      <td>-0.103591</td>\n",
       "      <td>0.218977</td>\n",
       "      <td>1.074359</td>\n",
       "      <td>0.097329</td>\n",
       "      <td>-0.830987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.064339</td>\n",
       "      <td>11.038403</td>\n",
       "      <td>-2.113861</td>\n",
       "      <td>-8.537898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11465</th>\n",
       "      <td>0.789283</td>\n",
       "      <td>-0.926166</td>\n",
       "      <td>-1.009343</td>\n",
       "      <td>0.086028</td>\n",
       "      <td>0.419751</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.369766</td>\n",
       "      <td>-0.334762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232654</td>\n",
       "      <td>-0.387918</td>\n",
       "      <td>4.879249</td>\n",
       "      <td>-0.905333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>-1.133488</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.611428</td>\n",
       "      <td>-0.111916</td>\n",
       "      <td>0.402818</td>\n",
       "      <td>-0.139944</td>\n",
       "      <td>0.425312</td>\n",
       "      <td>-0.704705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.263139</td>\n",
       "      <td>-0.329040</td>\n",
       "      <td>-3.599291</td>\n",
       "      <td>-1.656914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>0.649445</td>\n",
       "      <td>-0.748846</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>-0.678923</td>\n",
       "      <td>-0.245462</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>-0.196268</td>\n",
       "      <td>-0.899506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.459163</td>\n",
       "      <td>-1.926447</td>\n",
       "      <td>0.361546</td>\n",
       "      <td>4.583052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "10536   0.934115 -1.005494           -1.884754    -0.436118       -0.678455   \n",
       "12420   1.688241 -0.907501           -0.213514    -0.103591        0.218977   \n",
       "11465   0.789283 -0.926166           -1.009343     0.086028        0.419751   \n",
       "9862   -1.133488  0.445736           -0.611428    -0.111916        0.402818   \n",
       "4814    0.649445 -0.748846            0.821063    -0.678923       -0.245462   \n",
       "\n",
       "       population  households  median_income  ocean_proximity_1H OCEAN  \\\n",
       "10536   -0.705163   -0.706757       2.499136                       1.0   \n",
       "12420    1.074359    0.097329      -0.830987                       0.0   \n",
       "11465   -0.143439    0.369766      -0.334762                       0.0   \n",
       "9862    -0.139944    0.425312      -0.704705                       1.0   \n",
       "4814     0.378100   -0.196268      -0.899506                       1.0   \n",
       "\n",
       "       ocean_proximity_INLAND  ocean_proximity_NEAR BAY  \\\n",
       "10536                     0.0                       0.0   \n",
       "12420                     1.0                       0.0   \n",
       "11465                     0.0                       0.0   \n",
       "9862                      0.0                       0.0   \n",
       "4814                      0.0                       0.0   \n",
       "\n",
       "       ocean_proximity_NEAR OCEAN  rooms_per_household  \\\n",
       "10536                         0.0             0.617070   \n",
       "12420                         0.0            -1.064339   \n",
       "11465                         1.0             0.232654   \n",
       "9862                          0.0            -0.263139   \n",
       "4814                          0.0             3.459163   \n",
       "\n",
       "       population_per_household  bedrooms_per_room  income_per_household  \n",
       "10536                  0.997745           1.555668             -3.536063  \n",
       "12420                 11.038403          -2.113861             -8.537898  \n",
       "11465                 -0.387918           4.879249             -0.905333  \n",
       "9862                  -0.329040          -3.599291             -1.656914  \n",
       "4814                  -1.926447           0.361546              4.583052  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                 'total_bedrooms','population','households','median_income']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms']\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "# kao izlaznu vrijednost zelimo DataFrame strukturu\n",
    "ct1.set_output(transform='pandas')\n",
    "# iskljucujemo generiranje prefiska na kolonama \n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "\n",
    "\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train = predprocesor.fit_transform(X_train, y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treniranje modela\n",
    "\n",
    "Treniranje modela je proces u kome se model prilagodava podacima kako bi naucio odredene obrasce i veze.Proces treniranja podrazumijeva podešavanje unutrašnjih parametara modela kako bi se smanjila greska i povecala tocnost.U tom procesu se koriste podaci tako sto se ulazne karakteristike (atributi) povezuju sa odgovarajućim izlaznim vrijednostima, odnosno ciljnim promjenjivima. Zatim se dobija funkcionalan model koji je sposoban da vrsi predvidanja na osnovu podataka sa kojima se do tada nikada nije sreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot checking\n",
    "\n",
    "- pronalazak najboljeg algoritma za rjesavanje problema koristimo *spot-check* pristup sa kojim provjeravamo algoritme direktno nad trening podatcima.\n",
    "- koristimo **cross_val_score** za unakrsnu validaciju\n",
    "- tokom validacije koristi se tocnost *('accuracy')* - odnos tocno predvidenih klasa i ukupnog broja predvidanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kreirana je lista sa algoritmima masinskog ucenja, u for petlji je obavljen prolazak kroz listu i za svaki model je obavljena unakrsna validacija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    " \n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('DTR', DecisionTreeRegressor()))\n",
    "models.append(('RFR', RandomForestRegressor()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    " \n",
    " \n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=10)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f' % (name, cv_results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kao sto mozemo vidjeti najpogodniji algoritam za rjesavanje problema je *RandomForestRegressor*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForestRegressor** spada u grupu ensembla(ensembles) koji za svoje funckioniranje koristi veci broj stabala odlucivanja *(DecisionTreeRegressor)*, kombinacijom veceg broja algoritma postize se veca preciznost modela kao sto se moze i vidjeti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za podesavanje hiperparametara koristit cemo **mrezno pretrazivanje hiperparametara**.\n",
    "\n",
    "- koristi se pomocu klase **GridSearchCV** iz scikit-learn biblioteke\n",
    "- sufiks *CV* je skracenica za unakrsnu validaciju\n",
    "\n",
    "Rezultati mrežnog pretraživanja hiperparametara se mogu dobiti korišćenjem nekoliko svojstava objekta tipa *GridSearchCV*:\n",
    "- best_params_ – prikazuje najbolje vrednosti hiperparametara;\n",
    "- best_estimator_ – daje kompletan izgled poziva konstruktora klase za predviđanje sa najboljim hiperparametrima;\n",
    "- best_score_ – daje rezultat koji je ostvarila najbolja kombinacija hiperparametara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# ispis dostupnih hiperparametara \n",
    "rf = RandomForestRegressor().get_params()\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 70, 'max_features': 10, 'max_leaf_nodes': 500, 'n_estimators': 200}\n",
      "*************************************\n",
      "RandomForestRegressor(max_depth=70, max_features=10, max_leaf_nodes=500,\n",
      "                      n_estimators=200)\n",
      "*************************************\n",
      "0.8043075957703915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# rijecnik sa nazivima i vrijednostima hiperparametara\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_features': [10, 20, 30],\n",
    "    'max_depth': [30, 50, 70],\n",
    "    'max_leaf_nodes': [50, 200, 500]\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    " \n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(grid_search.best_params_)\n",
    "print(\"*************************************\")\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"*************************************\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobijeni rezultat je **0.8043075957703915**\n",
    "\n",
    "I sa podesavanjem hiperparametara model ima manji ucinak nego onaj sa podrazumijevanim vrijednostima.\n",
    "\n",
    "Sada prelazimo na evaluaciju modela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluaciju modela cemo izvrsiti sa koristenjem odgovarajucih metrika na **test skupu podataka**:\n",
    "- srednja apsolutna greška\n",
    "- srednja kvadratna greška\n",
    "- koeficijent determinacije ili r2 score\n",
    "\n",
    "\n",
    "Unutar *Pipeline* objekta smjestit cemo sve transformacije i objekt za kreiranje predvidanja.\n",
    "- koristimo *make_pipeline* funkciju kojom ne moramo dodatno definirati nazive razlicitih koraka, sve ostalo je identicno kao i konstruktor klase *Pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8161422696041528\n",
      "MAE: 33507.78645529882\n",
      "MSE: 2471224364.823578\n",
      "RMSE: 49711.41081103591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ababa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.head()\n",
    "\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                 'total_bedrooms','population','households','median_income']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms']\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "    ])\n",
    "\n",
    "\n",
    "full_pipeline = make_pipeline(\n",
    "    predprocesor,\n",
    "    RandomForestRegressor(min_samples_leaf=2, max_features=7, n_estimators=250, max_leaf_nodes=700)\n",
    ")\n",
    "\n",
    "# fitujemo podatke\n",
    "full_pipeline.fit(X_train,y_train)\n",
    "\n",
    "# vrsenje predikcije\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# metrike evaluacije\n",
    "r2_result = r2_score(y_test, y_pred)\n",
    "mae_result = mean_absolute_error(y_test, y_pred)\n",
    "mse_result = mean_squared_error(y_test, y_pred)\n",
    "rmse_result = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f'R2 Score: {r2_result}')\n",
    "print(f'MAE: {mae_result}')\n",
    "print(f'MSE: {mse_result}')\n",
    "print(f'RMSE: {rmse_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitanja i odgovori\n",
    "\n",
    "1. Koliko je model precizan?\n",
    "- preciznost modela je 0.816 koji govori koliko dobro skup predvidanja odgovara skpu ulaznih podataka.\n",
    "2. Koliko se poboljšao rad modela nakon podešavanja hiperparametara?\n",
    "- jako malo\n",
    "3. Šta je moguće uraditi da bi se dodatno poboljšala preciznost modela?\n",
    "- normalizirati ciljnu/target kolonu ako ima vece iskrivljenje(skewness), ali svakako RandomForestRegressor dobro se nosi sa iskrivljenim ciljim kolonama \n",
    "- selekcija karakteristika\n",
    "- primjeniti **Bayesovu** optimizaciju za napredno podesavanje hiperparametara pomocu biblioteka **Optuna ili Scikit-Optimize**\n",
    "- Kombinacijom predvidanja vise modela i koristenjem tehnike slaganja **StackingRegressor** koja pomaze u poboljsanju robusnosti i smanjenju varijance\n",
    "- regulacija kako bi se sprijecio **overfitting**\n",
    "- generirati jos karakteristika\n",
    "- dalje vrsiti unakrsnu validaciju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isprobao sam skoro sve metode za poboljsanje modela.\n",
    "\n",
    "Ispod je kod sa kojim sam uspio dobiti jako dobar score, generirao sam dvije karakteristike `'income_to_value_ratio'` omjer prihoda i vrijednosti kuca koju sam dobio: `data['median_income'] / data['median_house_value']`, generiranje se obavilo nakom podjele skupa podataka na trenazne i test da bi se izbjeglo curenje podataka, ima dobru korelaciju sa ciljnom karakteristikom i pokazuje da je korisna.\n",
    "Zatim `X['income_per_household'] = X['median_income'] / X['households']` prosjecni prihod po kucanstvu.\n",
    "\n",
    "Obavio sam i provjeru prilagodenosti modela u slucaju **overfittinga** - trenirao sam model na trenaznim i test skupovima, usporedio metrike i provjerio rezultate unakrsne validacije.\n",
    "1. train set u odnosu na test set\n",
    "- ako su rezultati train seta znatno bolji od test seta, to ukazuje na overfitting\n",
    "2. unakrsnom validacijom\n",
    "- rezultati unakrsne validacije R2 bi trebali biti blizu rezultata test seta R2\n",
    "- ako su rezultati unakrsne validacije konstantno visoki i blizu izvedbe test rezultata to pokazuje da je model dobro generaliziran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on training set: -5.094425366934393\n",
      "Bias on test set: 50.813992892909184\n",
      "Training R2: 0.9996626370993008, MAE: 632.4110620326782, MSE: 4471369.100760026\n",
      "Test R2: 0.9986183526818021, MAE: 1469.9713438862866, MSE: 18570666.07410397\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "\n",
    "# generiranje karakteristika nakon dijeljenja za sprijecavanje curenja podataka\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1) # + 1 da se izbjegne dijeljenje sa nulom\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "\n",
    "\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                 'total_bedrooms','population','households','median_income','income_to_value_ratio']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms']\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "    ])\n",
    "\n",
    "full_pipeline = make_pipeline(\n",
    "    predprocesor,\n",
    "    RandomForestRegressor()\n",
    ")\n",
    "\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# provjera ako je model overfitted\n",
    "# evaluacija na trenaznim podatcima\n",
    "y_train_pred = full_pipeline.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "bias_train = np.mean(y_train_pred - y_train)\n",
    "\n",
    "# evaluacija ne testnim podatcima\n",
    "y_test_pred = full_pipeline.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "bias_test = np.mean(y_test_pred - y_test)\n",
    "\n",
    "print(f\"Bias on training set: {bias_train}\")\n",
    "print(f\"Bias on test set: {bias_test}\")\n",
    "print(f\"Training R2: {train_r2}, MAE: {train_mae}, MSE: {train_mse}\")\n",
    "print(f\"Test R2: {test_r2}, MAE: {test_mae}, MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R2 scores: [0.99736735 0.99791946 0.99649498 0.99767109 0.99801111]\n",
      "Mean R2 score: 0.9974928006909323\n"
     ]
    }
   ],
   "source": [
    "# unakrsna provjera\n",
    "scores = cross_val_score(full_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R2 scores: {scores}\")\n",
    "print(f\"Mean R2 score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0.9986175368267771\n"
     ]
    }
   ],
   "source": [
    "# procjena funkcionalnosti modela\n",
    "\n",
    "full_pipeline.fit(X_train,y_train)\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('R2 Score', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varijanca cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "# Generate features after splitting to prevent data leakage\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1) # +1 to avoid division by zero\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "\n",
    "# Define feature categories\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                'total_bedrooms','population','households','median_income','income_to_value_ratio']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms']\n",
    "\n",
    "# Define transformers\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Define column transformer\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "], remainder='passthrough')\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "])\n",
    "\n",
    "# Define full pipeline\n",
    "full_pipeline = make_pipeline(\n",
    "    predprocesor,\n",
    "    RandomForestRegressor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingRegressor\n",
    "\n",
    "- najbolje rezultate pokazuje **HistGradientBoostingRegressor** (brzi je od obicnog gradient-a, i bolji za vece setove podataka =>10 000)\n",
    "\n",
    "- Gradient Boosting models provide strong predictive performance and have built-in regularization parameters such as learning_rate and l2_regularization, which can help in controlling overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DODAO SAM JOS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias on training set: 20.136104671372955\n",
      "Bias on test set: 99.20095726259302\n",
      "Training R2: 0.9973961349751433, MAE: 3015.81552938363, MSE: 34511327.68470552\n",
      "Test R2: 0.9964447335525671, MAE: 3307.8821179364613, MSE: 47786193.4302135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "data['income_latitude_interaction'] = data['median_income'] * data['latitude']\n",
    "data['income_longitude_interaction'] = data['median_income'] * data['longitude']\n",
    "\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "\n",
    "# generiranje karakteristika nakon dijeljenja za sprijecavanje curenja podataka\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1) # + 1 da se izbjegne dijeljenje sa nulom\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "X_train['median_income_squared'] = X_train['median_income'] ** 2\n",
    "X_test['median_income_squared'] = X_test['median_income'] ** 2\n",
    "\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                 'total_bedrooms','population','households','median_income','income_to_value_ratio','median_income_squared',\n",
    "                 'income_latitude_interaction','income_longitude_interaction']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms','median_icome']\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    #('rf', RandomForestRegressor(n_estimators=100,max_depth=20,min_samples_split=20,min_samples_leaf=10,random_state=42)),\n",
    "    #('xgb', XGBRegressor(n_estimators=100, random_state=42)),\n",
    "    #('gb', GradientBoostingRegressor(learning_rate=0.1, n_estimators=100,min_samples_leaf=5,min_samples_split=5,max_depth=10)),\n",
    "    ('hr', HistGradientBoostingRegressor(max_iter=100,max_depth=10,learning_rate=0.1,l2_regularization=0.1,max_bins=255,random_state=42))\n",
    "]\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "\n",
    "full_pipeline = make_pipeline(\n",
    "    predprocesor,\n",
    "    stacking_model\n",
    ")\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# provjera ako je model overfitted\n",
    "# evaluacija na trenaznim podatcima\n",
    "y_train_pred = full_pipeline.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "bias_train = np.mean(y_train_pred - y_train)\n",
    "\n",
    "# evaluacija ne testnim podatcima\n",
    "y_test_pred = full_pipeline.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "bias_test = np.mean(y_test_pred - y_test)\n",
    "\n",
    "print(f\"Bias on training set: {bias_train}\")\n",
    "print(f\"Bias on test set: {bias_test}\")\n",
    "print(f\"Training R2: {train_r2}, MAE: {train_mae}, MSE: {train_mse}\")\n",
    "print(f\"Test R2: {test_r2}, MAE: {test_mae}, MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias** blizu nule sugerira da model sustavno ne pretjerano ili premalo predviđa ciljnu varijablu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna hiperparametri RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "\n",
    "# generiranje karakteristika nakon dijeljenja za sprijecavanje curenja podataka\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1) # + 1 da se izbjegne dijeljenje sa nulom\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "\n",
    "\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "                 'total_bedrooms','population','households','median_income','income_to_value_ratio']\n",
    "features_to_generate = ['total_rooms','households','population','total_bedrooms']\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "    ])\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        predprocesor,\n",
    "        model\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    return -score.mean()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best cross-validation score: \", study.best_value)\n",
    "\n",
    "# Fit the model with the best parameters\n",
    "best_model = RandomForestRegressor(**study.best_params, random_state=42)\n",
    "full_pipeline = make_pipeline(predprocesor, best_model)\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model again\n",
    "y_train_pred = full_pipeline.predict(X_train)\n",
    "y_test_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"Metrics for {dataset_name} set:\")\n",
    "    print(f\"R²: {r2_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_true, y_pred)):.4f}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print_metrics(y_train, y_train_pred, \"Training\")\n",
    "print_metrics(y_test, y_test_pred, \"Testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regulariziran RFR - za smanjenje overfitinga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Training set:\n",
      "R²: 0.9978\n",
      "Mean Absolute Error: 1661.2488\n",
      "Mean Squared Error: 28682958.6529\n",
      "Root Mean Squared Error: 5355.6474\n",
      "\n",
      "Metrics for Testing set:\n",
      "R²: 0.9972\n",
      "Mean Absolute Error: 2020.3898\n",
      "Mean Squared Error: 38302707.6267\n",
      "Root Mean Squared Error: 6188.9181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "# Generate features after splitting to prevent data leakage\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1)  # +1 to avoid division by zero\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "\n",
    "# Define feature categories\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                'total_bedrooms', 'population', 'households', 'median_income','income_to_value_ratio']\n",
    "features_to_generate = ['total_rooms', 'households', 'population', 'total_bedrooms','median_icome']\n",
    "\n",
    "# Define transformers\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Define column transformer\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "], remainder='passthrough')\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "predprocesor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "])\n",
    "\n",
    "# Define the model with regularization parameters\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,         # Number of trees in the forest\n",
    "    max_depth=20,             # Maximum depth of the tree\n",
    "    min_samples_split=20,     # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=5,       # Minimum number of samples required to be at a leaf node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Define full pipeline\n",
    "full_pipeline = make_pipeline(\n",
    "    predprocesor,\n",
    "    model\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = full_pipeline.predict(X_train)\n",
    "\n",
    "# Predict on testing set\n",
    "y_test_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"Metrics for {dataset_name} set:\")\n",
    "    print(f\"R²: {r2_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_true, y_pred)):.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "print_metrics(y_train, y_train_pred, \"Training\")\n",
    "print_metrics(y_test, y_test_pred, \"Testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Underfitting vs Overfitting\n",
    "\n",
    "Interpretation:\n",
    "- R² (Coefficient of Determination): Closer to 1 indicates better model performance.\n",
    "- Mean Absolute Error (MAE): Lower values indicate better model performance.\n",
    "- Mean Squared Error (MSE): Lower values indicate better model performance.\n",
    "- Root Mean Squared Error (RMSE): Lower values indicate better model performance.\n",
    "\n",
    "By comparing these metrics for the training and testing sets, you can determine if the model is underfitting:\n",
    "\n",
    "- If the errors (MAE, MSE, RMSE) are high on both the training and testing sets, and R² is low, the model is likely underfitting.\n",
    "- If the training error is significantly lower than the testing error, it indicates overfitting.\n",
    "- Ideally, you want both training and testing errors to be low and similar, indicating good generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias-Variance Tradeoff: Understanding variance is essential to balance the bias-variance tradeoff. High variance indicates that the model is too sensitive to the training data, leading to overfitting. By evaluating the variance of a model, you can adjust its complexity to improve generalization.\n",
    "\n",
    "**Definitions**\n",
    "- Bias: Error due to overly simplistic models that cannot capture the underlying patterns in the data. High bias typically leads to underfitting.\n",
    "- Variance: Error due to models that are too complex and overly sensitive to the training data. High variance typically leads to overfitting.\n",
    "\n",
    "Bias-Variance Tradeoff\n",
    "- The goal is to find a balance between bias and variance to minimize the total error, which includes both these components and the irreducible error (noise inherent in the data). This tradeoff can be visualized as follows:\n",
    "\n",
    "- High Bias, Low Variance: The model is too simple, leading to systematic errors (underfitting). Predictions are consistent but inaccurate.\n",
    "- Low Bias, High Variance: The model is too complex, capturing noise along with the underlying data patterns (overfitting). Predictions are accurate on the training data but inconsistent on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating and Adjusting Variance\n",
    "\n",
    "Training vs. Validation Error:\n",
    "\n",
    "- High Bias: Both training and validation errors are high.\n",
    "- High Variance: Training error is low, but validation error is high.\n",
    "\n",
    "Model Complexity Adjustment:\n",
    "\n",
    "- For high bias, increase model complexity (e.g., add more features or use a more complex model).\n",
    "- For high variance, decrease model complexity (e.g., simplify the model, add regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from GenerateAttributes import GenerateAttributes\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset_full.csv')\n",
    "data.drop(data[data['ocean_proximity'].isin(['ISLAND'])].index, inplace=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=X['ocean_proximity'])\n",
    "\n",
    "# Generate features after splitting to prevent data leakage\n",
    "X_train['income_to_value_ratio'] = X_train['median_income'] / (y_train + 1)  # +1 to avoid division by zero\n",
    "X_test['income_to_value_ratio'] = X_test['median_income'] / (y_test + 1)\n",
    "\n",
    "# Define feature categories\n",
    "categories = ['ocean_proximity']\n",
    "num_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                'total_bedrooms', 'population', 'households', 'median_income', 'income_to_value_ratio']\n",
    "features_to_generate = ['total_rooms', 'households', 'population', 'total_bedrooms','median_icome']\n",
    "\n",
    "# Define transformers\n",
    "numerical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Define column transformer\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, categories)\n",
    "], remainder='passthrough')\n",
    "\n",
    "ct1.set_output(transform='pandas')\n",
    "ct1.verbose_feature_names_out = False\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = Pipeline([\n",
    "    ('ct1', ct1),\n",
    "    ('generate', GenerateAttributes(columns=features_to_generate))\n",
    "])\n",
    "\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    #('rf', RandomForestRegressor(n_estimators=100,max_depth=20,min_samples_split=20,min_samples_leaf=10,random_state=42)),\n",
    "    #('xgb', XGBRegressor(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(learning_rate=0.1, n_estimators=100,min_samples_leaf=5,min_samples_split=5,max_depth=10)),\n",
    "    ('hr', HistGradientBoostingRegressor(max_iter=100,max_depth=10,learning_rate=0.1,l2_regularization=0.1,max_bins=255,random_state=42))\n",
    "]\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=Ridge(alpha=1.0)\n",
    ")\n",
    "\n",
    "\n",
    "# Define the model pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', stacking_model)\n",
    "])\n",
    "\n",
    "# Define custom scoring functions\n",
    "def bias_scorer(y_true, y_pred):\n",
    "    return np.mean(y_pred - y_true)\n",
    "\n",
    "scoring = {\n",
    "    'neg_mean_squared_error': 'neg_mean_squared_error',\n",
    "    'neg_mean_absolute_error': 'neg_mean_absolute_error',\n",
    "    'r2': 'r2',\n",
    "    'bias': make_scorer(bias_scorer)\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(model_pipeline, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "# Extract and convert negative scores to positive\n",
    "train_mse_scores = -cv_results['train_neg_mean_squared_error']\n",
    "test_mse_scores = -cv_results['test_neg_mean_squared_error']\n",
    "train_mae_scores = -cv_results['train_neg_mean_absolute_error']\n",
    "test_mae_scores = -cv_results['test_neg_mean_absolute_error']\n",
    "train_r2_scores = cv_results['train_r2']\n",
    "test_r2_scores = cv_results['test_r2']\n",
    "train_bias_scores = cv_results['train_bias']\n",
    "test_bias_scores = cv_results['test_bias']\n",
    "\n",
    "# Compute mean and variance for each metric\n",
    "metrics = {\n",
    "    \"Train MSE\": train_mse_scores,\n",
    "    \"Test MSE\": test_mse_scores,\n",
    "    \"Train MAE\": train_mae_scores,\n",
    "    \"Test MAE\": test_mae_scores,\n",
    "    \"Train R2\": train_r2_scores,\n",
    "    \"Test R2\": test_r2_scores,\n",
    "    \"Train Bias\": train_bias_scores,\n",
    "    \"Test Bias\": test_bias_scores\n",
    "}\n",
    "\n",
    "for metric_name, values in metrics.items():\n",
    "    mean_value = np.mean(values)\n",
    "    variance_value = np.var(values)\n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  Mean: {mean_value}\")\n",
    "    print(f\"  Variance: {variance_value}\")\n",
    "    print(f\"  Values: {values}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
